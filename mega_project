import math
import mediapipe as mp
import cv2

# Initialize MediaPipe Pose solution
mp_pose = mp.solutions.pose
mp_hands = mp.solutions.hands
mp_face_detection = mp.solutions.face_detection
face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.5)

pose = mp_pose.Pose()
hands = mp_hands.Hands()

mp_face_mesh = mp.solutions.face_mesh
face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)


# Initialize MediaPipe Drawing Utilities for visualization
mp_drawing = mp.solutions.drawing_utils

# Initialize maximum distance
max_distance = float('-inf')
max_distance_bow = float('-inf')

# Initialize MediaPipe Pose and Hand solutions
with mp_pose.Pose() as pose, mp_hands.Hands() as hands:
    # Start webcam capture
    cap = cv2.VideoCapture(0)

    while cap.isOpened():
        success, image = cap.read()
        if not success:
            print("Ignoring empty camera frame.")
            continue

        # Convert the BGR image to RGB (MediaPipe uses RGB)
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # Process the image to get pose landmarks
        results = pose.process(image_rgb)

        # Process the image to get hand landmarks
        hand_results = hands.process(image_rgb)

        # Detect faces in the image
        results_detection = face_detection.process(image_rgb)

        if results_detection.detections:
            for detection in results_detection.detections:
                bboxC = detection.location_data.relative_bounding_box
                ih, iw, _ = image.shape
        # Perform face landmark detection
        results_landmarks = face_mesh.process(image_rgb)
                    
        # Draw the landmarks and connections on the image
        annotated_image = image.copy()  # Create a copy of the original image
        if results.pose_landmarks:
            mp_drawing.draw_landmarks(
                annotated_image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)

        # Calculate the approximate position of the mouth
        landmarks = results.pose_landmarks
        if landmarks:
            # Approximate mouth position by taking the average of the landmarks corresponding to the lips
            mouth_x = (landmarks.landmark[mp_pose.PoseLandmark.MOUTH_LEFT].x + landmarks.landmark[mp_pose.PoseLandmark.MOUTH_RIGHT].x) / 2
            mouth_y = (landmarks.landmark[mp_pose.PoseLandmark.MOUTH_LEFT].y + landmarks.landmark[mp_pose.PoseLandmark.MOUTH_RIGHT].y) / 2

            # Calculate the distance between shoulder and mouth landmarks
            shoulder = landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER]
            distance = math.sqrt((shoulder.x - mouth_x)**2 + (shoulder.y - mouth_y)**2)
        
        # Draw hand landmarks if available
        if hand_results.multi_hand_landmarks:
            for hand_landmarks in hand_results.multi_hand_landmarks:
                mp_drawing.draw_landmarks(annotated_image, hand_landmarks, mp_hands.HAND_CONNECTIONS)

        if results_landmarks.multi_face_landmarks:
            for face_landmarks in results_landmarks.multi_face_landmarks:
                for landmark in face_landmarks.landmark:
                    cx, cy = int(landmark.x * iw), int(landmark.y * ih)
                    cv2.circle(annotated_image, (cx, cy), 1, (255, 255, 255), -1)

        # Display the annotated image
        cv2.imshow('MediaPipe Pose', annotated_image)

        # Check for the 'Esc' key to exit
        if cv2.waitKey(5) & 0xFF == 27:
            break

    # Release the webcam and close all OpenCV windows
    cap.release()
    cv2.destroyAllWindows()
